{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kimsh\\Anaconda3\\envs\\env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\kimsh\\Anaconda3\\envs\\env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\kimsh\\Anaconda3\\envs\\env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\kimsh\\Anaconda3\\envs\\env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\kimsh\\Anaconda3\\envs\\env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\kimsh\\Anaconda3\\envs\\env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, BatchNormalization\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "import cvlib as cv\n",
    "import cv2\n",
    "import face_recognition\n",
    "\n",
    "from PIL import ImageFont, ImageDraw, Image\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\kimsh\\Anaconda3\\envs\\env\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\kimsh\\Anaconda3\\envs\\env\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet50 (Model)             (None, 7, 7, 2048)        23587712  \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 100352)            0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 128)               12845184  \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_1 (Ba (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 36,433,537\n",
      "Trainable params: 36,380,161\n",
      "Non-trainable params: 53,376\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = load_model('models/model.h5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kimsh\\[K-Digital] MLDL\\Semi-project 3 (데이터 수집-전처리-통계분석-시각화 + ML _ DL)_PM\\maskdata\\face_recognition\\knowns\n"
     ]
    }
   ],
   "source": [
    "# 경로 변경\n",
    "cd ./maskdata/face_recognition/knowns/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\kimsh\\\\[K-Digital] MLDL\\\\Semi-project 3 (데이터 수집-전처리-통계분석-시각화 + ML _ DL)_PM\\\\maskdata\\\\face_recognition\\\\knowns'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curr_path = os.getcwd()\n",
    "curr_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['kimsoohee.jpg']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "known_face_dir = os.listdir('./')\n",
    "known_face_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 아는 얼굴들 미리 모아놓기\n",
    "\n",
    "known_face_encodings = []\n",
    "known_user_names = []\n",
    "error_user_list = []\n",
    "\n",
    "for known_face_user in known_face_dir:\n",
    "    \n",
    "    known_user_image = face_recognition.load_image_file(known_face_user)\n",
    "    \n",
    "    try:\n",
    "        known_user_encoding = face_recognition.face_encodings(known_user_image)[0]\n",
    "        known_face_encodings.append(known_user_encoding)\n",
    "        known_user_names.append(known_face_user[:-4])\n",
    "        \n",
    "    except:\n",
    "        print(f\"{known_face_user[:-4]}의 얼굴인식이 되지 않습니다.재촬영이 필요합니다.\")\n",
    "        error_user_list.append(known_face_user)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def known_face_name(frame, known_face_encodings, known_user_names):\n",
    "    face_locations = []\n",
    "    face_encodings = []\n",
    "    face_names = []\n",
    "    process_this_frame = True\n",
    "    name = \"Unknown\"\n",
    "\n",
    "    # 얼굴 인식 처리 속도를 높이기 위해 비디오 프레임 크기를 1/4 크기로 조정\n",
    "    small_frame = cv2.resize(frame, (0, 0), fx=0.25, fy=0.25)\n",
    "\n",
    "    # 영상을 BGR 색상(OpenCV가 사용하는)에서 RGB 색상(페이스_인식 사용)으로 변환\n",
    "    rgb_small_frame = small_frame[:, :, ::-1]\n",
    "\n",
    "    # 다른 모든 비디오 프레임만 처리하여 시간 절약\n",
    "    if process_this_frame:\n",
    "        # 현재 비디오 프레임에서 모든 얼굴 및 얼굴 인코딩 찾기\n",
    "        face_locations = face_recognition.face_locations(rgb_small_frame)\n",
    "        face_encodings = face_recognition.face_encodings(rgb_small_frame, face_locations)\n",
    "\n",
    "        face_names = []\n",
    "        for face_encoding in face_encodings:\n",
    "            # 얼굴이 known face(s)와 일치하는지 확인\n",
    "            matches = face_recognition.compare_faces(known_face_encodings, face_encoding)\n",
    "            \n",
    "            # # known_face_encodings에서 일치하는 항목이 발견되면 첫 번째 항목을 사용\n",
    "            # 일치하는 경우:\n",
    "            # first_match_index =이(가) 일치합니다.index(참)\n",
    "            # name = knowled_face_names[first_match_index]\n",
    "\n",
    "            # 대신 새 얼굴까지의 거리가 가장 작은 알려진 얼굴을 사용합니다.\n",
    "            face_distances = face_recognition.face_distance(known_face_encodings, face_encoding)\n",
    "            best_match_index = np.argmin(face_distances)\n",
    "            if matches[best_match_index]:\n",
    "                name = known_user_names[best_match_index]\n",
    "\n",
    "        return name\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_capture = cv2.VideoCapture(0)\n",
    "face_locations = []\n",
    "face_encodings = []\n",
    "face_names = []\n",
    "process_this_frame = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kimsh\\[K-Digital] MLDL\\Semi-project 3 (데이터 수집-전처리-통계분석-시각화 + ML _ DL)_PM\\maskdata\\face_recognition\n"
     ]
    }
   ],
   "source": [
    "# 상위 폴더로 올라가놓기\n",
    "cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\kimsh\\\\[K-Digital] MLDL\\\\Semi-project 3 (데이터 수집-전처리-통계분석-시각화 + ML _ DL)_PM\\\\maskdata\\\\face_recognition'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curr_path = os.getcwd()\n",
    "curr_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name_path->>>> ./nomask_capture/kimsoohee\n",
      "./nomask_capture/kimsoohee/kimsoohee2021_01_31_15_05_28.png\n",
      "name_path->>>> ./nomask_capture/kimsoohee\n",
      "./nomask_capture/kimsoohee/kimsoohee2021_01_31_15_05_29.png\n",
      "name_path->>>> ./nomask_capture/kimsoohee\n",
      "./nomask_capture/kimsoohee/kimsoohee2021_01_31_15_05_30.png\n",
      "name_path->>>> ./nomask_capture/kimsoohee\n",
      "./nomask_capture/kimsoohee/kimsoohee2021_01_31_15_05_31.png\n",
      "listPath->> C:\\Users\\kimsh\\[K-Digital] MLDL\\Semi-project 3 (데이터 수집-전처리-통계분석-시각화 + ML _ DL)_PM\\maskdata\\face_recognition\\nomask_list\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "nomask_info = []\n",
    "\n",
    "# open webcam\n",
    "webcam = cv2.VideoCapture(0)\n",
    " \n",
    "if not webcam.isOpened():\n",
    "    print(\"Could not open webcam\")\n",
    "    exit()\n",
    "    \n",
    " \n",
    "# loop through frames\n",
    "while webcam.isOpened():\n",
    " \n",
    "    # read frame from webcam \n",
    "    status, frame = webcam.read()\n",
    "    \n",
    "    if not status:\n",
    "        print(\"Could not read frame\")\n",
    "        exit()\n",
    " \n",
    "    # apply face detection\n",
    "    face, confidence = cv.detect_face(frame)\n",
    " \n",
    "    # loop through detected faces\n",
    "    for idx, f in enumerate(face):\n",
    "        \n",
    "        (startX, startY) = f[0], f[1]\n",
    "        (endX, endY) = f[2], f[3]\n",
    "        \n",
    "        if 0 <= startX <= frame.shape[1] and 0 <= endX <= frame.shape[1] and 0 <= startY <= frame.shape[0] and 0 <= endY <= frame.shape[0]:\n",
    "            \n",
    "            face_region = frame[startY:endY, startX:endX]\n",
    "            \n",
    "            face_region1 = cv2.resize(face_region, (224, 224), interpolation = cv2.INTER_AREA)\n",
    "            \n",
    "            x = img_to_array(face_region1)\n",
    "            x = np.expand_dims(x, axis=0)\n",
    "            x = preprocess_input(x)\n",
    "            \n",
    "            prediction = model.predict(x)\n",
    " \n",
    "            if prediction < 0.5: # 마스크 미착용으로 판별되면, \n",
    "                result_name = known_face_name(frame, known_face_encodings, known_user_names)\n",
    "#                 print(result_name)\n",
    "                cv2.rectangle(frame, (startX,startY), (endX,endY), (0,0,255), 2)\n",
    "                Y = startY - 10 if startY - 10 > 10 else startY + 10\n",
    "                text = \"No Mask ({:.2f}%)\".format((1 - prediction[0][0])*100)\n",
    "                result_text = result_name + \" is \" + text\n",
    "                cv2.putText(frame, result_text, (startX,Y), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,0,255), 2)\n",
    "                \n",
    "                # 이미지 저장\n",
    "#                 now_time = datetime.now().strftime('%Y_%m_%d_%H_%M_%S') \n",
    "                now_time = datetime.now().strftime('%Y_%m_%d_%H_%M_%S') \n",
    "                #초단위라서 여러장 나옴 #이 위에 중복인물인지 체크하는 함수와 if문으로 저장 필요%H%M%S\n",
    "#                 temp_time = now_time[:17]\n",
    "                \n",
    "                # 사용자에 따라서 폴더 만들기\n",
    "                nomask_capture_path = './nomask_capture/'\n",
    "                now_time = datetime.now().strftime('%Y_%m_%d_%H_%M_%S') \n",
    "                name_path = nomask_capture_path + result_name\n",
    "#                 print(\"name_path->>>>\", name_path)\n",
    "                \n",
    "                if not os.path.isdir(name_path):\n",
    "                    os.mkdir(name_path)\n",
    "\n",
    "                img_name = f\"{name_path}/{result_name}{now_time}.png\".format(name_path, result_name, now_time)\n",
    "                cv2.imwrite(img_name, frame)    \n",
    "#                 print(img_name)\n",
    "                nomask_info.append((result_name, now_time))\n",
    "\n",
    "#                 os.chdir('../')\n",
    "                \n",
    "            else: # 마스크 착용으로 판별되면\n",
    "                cv2.rectangle(frame, (startX,startY), (endX,endY), (0,255,0), 2)\n",
    "                Y = startY - 10 if startY - 10 > 10 else startY + 10\n",
    "                text = \"Mask ({:.2f}%)\".format(prediction[0][0]*100)\n",
    "                cv2.putText(frame, text, (startX,Y), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,255,0), 2)\n",
    "                \n",
    "    # display output\n",
    "    cv2.imshow(\"mask nomask classify\", frame)\n",
    " \n",
    "    # press \"Q\" to stop\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        df = pd.DataFrame(nomask_info, columns=['name', 'date_time'])\n",
    "        \n",
    "        list_path = curr_path + '\\\\nomask_list'\n",
    "        print(\"listPath->>\", list_path)\n",
    "        if not os.path.isdir(list_path):                                                           \n",
    "            os.mkdir(list_path)\n",
    "            \n",
    "        df.to_excel('{}\\\\nomask_list_{}.xlsx'.format(list_path, datetime.now().strftime('%Y_%m_%d')))\n",
    "        break\n",
    "    \n",
    "# release resources\n",
    "webcam.release()\n",
    "cv2.destroyAllWindows() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# release resources\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
